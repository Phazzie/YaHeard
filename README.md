# Multi-AI Transcription Consensus Engine

ğŸš€ **@Phazzie Contract-Driven Development Mode ACTIVATED!**

A SvelteKit application that processes audio files through multiple AI transcription services (Whisper, AssemblyAI, Deepgram) and generates consensus transcriptions for improved accuracy. This project has been refactored to use a robust, asynchronous architecture suitable for serverless deployment on Vercel.

## ğŸ—ï¸ Asynchronous Architecture

The application now uses an asynchronous, job-based architecture to handle long-running transcription tasks without timing out.

1.  **Client-Side Upload**: The user selects a file, and the frontend requests a secure upload URL from the SvelteKit backend.
2.  **Direct Blob Storage**: The client uploads the file directly to Vercel Blob storage, bypassing serverless function payload limits.
3.  **Background Job**: After the upload, the client triggers a Vercel Background Function to process the file.
4.  **Polling for Results**: The client polls a status endpoint to check the job's progress and retrieve the final transcription results once they are stored in Vercel KV.

This design ensures scalability and reliability.

### Project Structure
```
src/
â”œâ”€â”€ contracts/           # ğŸ“‹ Interfaces that DON'T change
â”‚   â”œâ”€â”€ transcription.ts
â”‚   â””â”€â”€ processors.ts
â”‚
â”œâ”€â”€ implementations/     # ğŸ”„ Can be regenerated freely
â”‚   â”œâ”€â”€ whisper.ts
â”‚   â””â”€â”€ assembly.ts
â”‚
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ +page.svelte     # Main UI with polling logic
â”‚   â”œâ”€â”€ +page.server.ts  # Generates signed URLs for Vercel Blob
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ process-transcription/ # Vercel Background Function
â”‚       â”‚   â””â”€â”€ +server.ts
â”‚       â””â”€â”€ status/[jobId]/        # Polling endpoint for job status
â”‚           â””â”€â”€ +server.ts
â”‚
â””â”€â”€ lib/components/      # Reusable UI components
    â”œâ”€â”€ FileUpload.svelte
    â”œâ”€â”€ ResultsDisplay.svelte
    â””â”€â”€ ProgressBar.svelte
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- npm or yarn
- Vercel account with Blob and KV stores configured.

### Environment Variables
Create a `.env` file and populate it with the required Vercel storage credentials and AI service API keys:
```
# Vercel Storage
BLOB_READ_WRITE_TOKEN=
KV_URL=
KV_REST_API_URL=
KV_REST_API_TOKEN=
KV_REST_API_READ_ONLY_TOKEN=

# AI Services (at least one is required)
OPENAI_API_KEY=
ASSEMBLYAI_API_KEY=
DEEPGRAM_API_KEY=
GEMINI_API_KEY=
ELEVENLABS_API_KEY=
```

### Installation
```bash
npm install
```

### Development
```bash
npm run dev
```

## ğŸ”„ Current Status
- **Architecture**: âœ… Asynchronous, scalable, and ready for Vercel.
- **Contracts**: âœ… Defined and stable.
- **UI Components**: âœ… Working with polling and displays async results.
- **File Upload**: âœ… Using Vercel Blob for large file uploads.
- **AI Implementations**: âœ… Fully integrated into the background processing pipeline.
- **Consensus Algorithm**: âœ… Refactored to use Levenshtein distance for robust results.

## ğŸš€ Deployment
This project is architected for Vercel.

1.  **Configure Project**: Set up the environment variables listed above in your Vercel project settings. Ensure Vercel Blob and KV stores are linked.
2.  **Deploy**: Connect your Git repository to Vercel for automatic deployments.

```bash
npm run build
# Deploy to Vercel
```

## ğŸ“ Adding New AI Services
1.  Create a new implementation file in `src/implementations/` that adheres to the `AudioProcessor` interface in `src/contracts/processors.ts`.
2.  Add the new service to the processing pipeline in `src/routes/api/process-transcription/+server.ts`.
3.  Add the corresponding API key to your environment variables.

---

**Built with â¤ï¸ for @Phazzie's regeneration-over-debug workflow**

*Time: 2025-08-30 | Status: Refactored for Asynchronous Vercel Deployment*
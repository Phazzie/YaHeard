# Consensus Algorithm Explanation

The Multi-AI Transcription Engine uses a consensus algorithm to determine the most accurate transcription from a pool of results generated by different AI services. The original algorithm was replaced because it was based on unreliable, self-reported "confidence" scores. The new, more robust algorithm works by directly analyzing the text of the transcriptions.

## Core Method: Levenshtein Distance

The new algorithm is centered around the **Levenshtein distance**.

-   **What it is:** A well-established algorithm that measures the "edit distance" between two strings.
-   **How it works:** It calculates the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one string into the other.
-   **Example:** The Levenshtein distance between "saturday" and "sunday" is 3 (delete 'a', delete 't', replace 'r' with 'n'). A lower distance means the strings are more similar.

## The Consensus Process

1.  **Filter for Success:** The algorithm first filters out any failed AI services and only considers successful transcriptions with actual text content.

2.  **Calculate Average Distance:** For each successful transcription, it calculates its average Levenshtein distance to **all other** successful transcriptions. This gives us a score of how "central" each transcription is to the entire group.

3.  **Select the Winner:** The transcription with the **lowest average distance** is chosen as the consensus result. This is the one that is most textually similar to its peers and is therefore the most likely candidate for the correct transcription.

4.  **Calculate Agreement Score:** The final "agreement percentage" is also calculated based on text similarity. It represents the average similarity of the winning text to all other results, providing a more meaningful metric of consensus than the original implementation.

This method ensures that the final result is a true consensus based on the textual evidence from all the AI services, rather than relying on flawed or arbitrary confidence scores.
